{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3e2055",
   "metadata": {},
   "source": [
    "# Introduction to Breast Cancer Classification using Logistic Regression\n",
    "\n",
    "## Project Overview\n",
    "In this Jupyter Notebook, we will tackle the problem of classifying breast cancer cases into malignant or benign categories using logistic regression, a fundamental technique in machine learning. The dataset utilized in this project is the Breast Cancer dataset provided by scikit-learn, which includes various features such as mean radius, texture, and area of the cancer cells.\n",
    "\n",
    "## Objective\n",
    "The main goal is to develop a logistic regression model to accurately predict whether a case is malignant or benign based on the features provided in the dataset. This model will help in understanding the applicability of logistic regression in medical diagnosis.\n",
    "\n",
    "## Steps Covered\n",
    "1. **Data Loading:** Import the dataset from scikit-learn and examine its structure.\n",
    "2. **Data Preparation:** Process and split the dataset into training and testing sets to ensure a fair assessment of the model's performance.\n",
    "3. **Model Training:** Train a logistic regression model using the training data.\n",
    "4. **Model Evaluation:** Evaluate the model's accuracy and effectiveness using the testing set.\n",
    "5. **Result Visualization:** Display results and metrics, such as confusion matrices and classification reports, to interpret the model's performance.\n",
    "\n",
    "## Conclusion\n",
    "This notebook will provide insights into the basic application of logistic regression in binary classification tasks, particularly in a healthcare context. By the end, we will have a clear understanding of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2e1c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n",
      "ERROR: Invalid requirement: '#'\n",
      "ERROR: Invalid requirement: '#'\n",
      "ERROR: Invalid requirement: '#'\n",
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas  # Install pandas library for data manipulation and analysis\n",
    "!pip install numpy  # Install numpy library for numerical computations\n",
    "!pip install matplotlib  # Install matplotlib library for creating visualizations\n",
    "!pip install seaborn  # Install seaborn library for statistical data visualization\n",
    "!pip install scikit-learn  # Install scikit-learn library for machine learning algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7222f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Importing Pandas library and aliasing it as pd for easier usage\n",
    "import numpy as np   # Importing NumPy library and aliasing it as np for easier usage\n",
    "import matplotlib.pyplot as plt  # Importing Matplotlib's pyplot module and aliasing it as plt for easier usage\n",
    "import seaborn as sns  # Importing Seaborn library and aliasing it as sns for easier usage\n",
    "from sklearn.model_selection import train_test_split  # Importing train_test_split function from scikit-learn's model_selection module\n",
    "from sklearn.linear_model import LogisticRegression  # Importing LogisticRegression class from scikit-learn's linear_model module\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  # Importing specific evaluation metrics from scikit-learn's metrics module\n",
    "from sklearn.datasets import load_breast_cancer  # Importing load_breast_cancer dataset from scikit-learn's datasets module\n",
    "from sklearn.preprocessing import StandardScaler  # Importing StandardScaler for feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced3217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()  # Loads the breast cancer dataset from scikit-learn into the variable 'data'\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)  # Creates a Pandas DataFrame 'df' with dataset's data and feature names as columns\n",
    "df['target'] = data.target  # Adds a new column 'target' to the DataFrame containing the target labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893c786c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7baf004",
   "metadata": {},
   "source": [
    "# List of All Columns:\n",
    "\n",
    "1. **mean radius**: Average size of the cell nuclei.\n",
    "2. **mean texture**: Standard deviation of gray-scale values.\n",
    "3. **mean perimeter**: Average perimeter of the cell nuclei.\n",
    "4. **mean area**: Average area of the cell nuclei.\n",
    "5. **mean smoothness**: Measure of the smoothness of the cell nuclei.\n",
    "6. **mean compactness**: Measure of the compactness of the cell nuclei.\n",
    "7. **mean concavity**: Measure of the concavity of the cell nuclei.\n",
    "8. **mean concave points**: Number of concave portions of the contour.\n",
    "9. **mean symmetry**: Measure of the symmetry of the cell nuclei.\n",
    "10. **mean fractal dimension**: Measure of the complexity of the cell nuclei's border.\n",
    "11. **radius error**: Standard error of the radius.\n",
    "12. **texture error**: Standard error of the texture.\n",
    "13. **perimeter error**: Standard error of the perimeter.\n",
    "14. **area error**: Standard error of the area.\n",
    "15. **smoothness error**: Standard error of the smoothness.\n",
    "16. **compactness error**: Standard error of the compactness.\n",
    "17. **concavity error**: Standard error of the concavity.\n",
    "18. **concave points error**: Standard error of the concave points.\n",
    "19. **symmetry error**: Standard error of the symmetry.\n",
    "20. **fractal dimension error**: Standard error of the fractal dimension.\n",
    "21. **worst radius**: Largest value of the radius.\n",
    "22. **worst texture**: Largest value of the texture.\n",
    "23. **worst perimeter**: Largest value of the perimeter.\n",
    "24. **worst area**: Largest value of the area.\n",
    "25. **worst smoothness**: Largest value of the smoothness.\n",
    "26. **worst compactness**: Largest value of the compactness.\n",
    "27. **worst concavity**: Largest value of the concavity.\n",
    "28. **worst concave points**: Largest number of concave points.\n",
    "29. **worst symmetry**: Largest value of the symmetry.\n",
    "30. **worst fractal dimension**: Largest value of the fractal dimension.\n",
    "31. **target**: Diagnosis of the cancer (0: benign, 1: malignant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2b0724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0aa6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('target', axis=1)  # Creates a new DataFrame 'X' containing features (all columns except 'target')\n",
    "y = df['target']  # Creates a Series 'y' containing the target labels\n",
    "\n",
    "# Splits the data into training and testing sets using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()  # Creating a StandardScaler object for feature scaling\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fitting the scaler to the training data and transforming it\n",
    "X_test_scaled = scaler.transform(X_test)  # Transforming the test data using the fitted scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5161ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=10000, solver='liblinear', penalty='l2', C=1.0)\n",
    "# 'max_iter=10000' sets the maximum number of iterations for the solver to converge.\n",
    "# 'solver='liblinear'' specifies the optimization algorithm suitable for small datasets.\n",
    "# 'penalty='l2'' applies L2 regularization to prevent overfitting.\n",
    "# 'C=1.0' sets the inverse of regularization strength, with smaller values indicating stronger regularization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d8865",
   "metadata": {},
   "source": [
    "### Initializing Logistic Regression Model\n",
    "\n",
    "We're setting up a logistic regression model using scikit-learn's LogisticRegression class with the following configurations:\n",
    "\n",
    "- `max_iter=10000`: This sets the maximum number of iterations the solver can take to converge. Increasing this number allows the solver more chances to find the best solution, which is useful for more complex datasets.\n",
    "  \n",
    "- `solver='liblinear'`: This specifies the method used by the model to solve the optimization problem. 'liblinear' is suitable for small to medium-sized datasets and generally provides a good balance of speed and performance.\n",
    "\n",
    "- `penalty='l2'`: This refers to the type of regularization used. 'l2' regularization penalizes large coefficients in the model to prevent overfitting, which occurs when a model learns too much noise from the training data.\n",
    "\n",
    "- `C=1.0`: This parameter controls the regularization strength, where smaller values of `C` mean stronger regularization. Regularization helps to prevent the model from fitting too closely to the training data and potentially improving its ability to generalize to new, unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf6ca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='liblinear')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fits the logistic regression model using the training data X_train and corresponding labels y_train\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c1f8b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts the target labels for the test data X_test using the trained logistic regression model\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0535304f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual_Interpretation</th>\n",
       "      <th>Predicted_Interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Cancer</td>\n",
       "      <td>No Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted Actual_Interpretation Predicted_Interpretation\n",
       "204       1          1                Cancer                   Cancer\n",
       "70        0          0             No Cancer                No Cancer\n",
       "131       0          0             No Cancer                No Cancer\n",
       "431       1          1                Cancer                   Cancer\n",
       "540       1          1                Cancer                   Cancer\n",
       "567       0          0             No Cancer                No Cancer\n",
       "369       0          0             No Cancer                No Cancer\n",
       "29        0          0             No Cancer                No Cancer\n",
       "81        1          1                Cancer                   Cancer\n",
       "477       1          1                Cancer                   Cancer\n",
       "457       1          1                Cancer                   Cancer\n",
       "167       0          0             No Cancer                No Cancer\n",
       "165       1          1                Cancer                   Cancer\n",
       "329       0          0             No Cancer                No Cancer\n",
       "527       1          1                Cancer                   Cancer\n",
       "83        0          0             No Cancer                No Cancer\n",
       "511       1          1                Cancer                   Cancer\n",
       "556       1          1                Cancer                   Cancer\n",
       "101       1          1                Cancer                   Cancer\n",
       "535       0          0             No Cancer                No Cancer\n",
       "73        0          1             No Cancer                   Cancer\n",
       "394       1          1                Cancer                   Cancer\n",
       "393       0          0             No Cancer                No Cancer\n",
       "425       1          1                Cancer                   Cancer\n",
       "305       1          1                Cancer                   Cancer\n",
       "76        1          1                Cancer                   Cancer\n",
       "384       1          1                Cancer                   Cancer\n",
       "555       1          1                Cancer                   Cancer\n",
       "362       1          1                Cancer                   Cancer\n",
       "72        0          0             No Cancer                No Cancer\n",
       "551       1          1                Cancer                   Cancer\n",
       "158       1          1                Cancer                   Cancer\n",
       "424       1          1                Cancer                   Cancer\n",
       "532       1          1                Cancer                   Cancer\n",
       "222       1          1                Cancer                   Cancer\n",
       "55        1          1                Cancer                   Cancer\n",
       "10        0          0             No Cancer                No Cancer\n",
       "281       1          1                Cancer                   Cancer\n",
       "6         0          0             No Cancer                No Cancer\n",
       "90        1          1                Cancer                   Cancer\n",
       "104       1          1                Cancer                   Cancer\n",
       "353       0          0             No Cancer                No Cancer\n",
       "422       1          1                Cancer                   Cancer\n",
       "211       1          1                Cancer                   Cancer\n",
       "275       1          1                Cancer                   Cancer\n",
       "109       1          1                Cancer                   Cancer\n",
       "520       1          1                Cancer                   Cancer\n",
       "557       1          1                Cancer                   Cancer\n",
       "531       1          1                Cancer                   Cancer\n",
       "284       1          1                Cancer                   Cancer\n",
       "264       0          0             No Cancer                No Cancer\n",
       "30        0          0             No Cancer                No Cancer\n",
       "208       1          1                Cancer                   Cancer\n",
       "528       1          1                Cancer                   Cancer\n",
       "145       1          1                Cancer                   Cancer\n",
       "464       1          1                Cancer                   Cancer\n",
       "320       1          1                Cancer                   Cancer\n",
       "82        0          0             No Cancer                No Cancer\n",
       "39        0          0             No Cancer                No Cancer\n",
       "271       1          1                Cancer                   Cancer\n",
       "79        1          1                Cancer                   Cancer\n",
       "2         0          0             No Cancer                No Cancer\n",
       "564       0          0             No Cancer                No Cancer\n",
       "462       1          1                Cancer                   Cancer\n",
       "334       1          1                Cancer                   Cancer\n",
       "228       1          1                Cancer                   Cancer\n",
       "118       0          0             No Cancer                No Cancer\n",
       "78        0          0             No Cancer                No Cancer\n",
       "188       1          1                Cancer                   Cancer\n",
       "331       1          1                Cancer                   Cancer\n",
       "196       0          0             No Cancer                No Cancer\n",
       "11        0          0             No Cancer                No Cancer\n",
       "395       1          1                Cancer                   Cancer\n",
       "177       0          0             No Cancer                No Cancer\n",
       "538       1          1                Cancer                   Cancer\n",
       "482       1          1                Cancer                   Cancer\n",
       "235       1          1                Cancer                   Cancer\n",
       "255       0          1             No Cancer                   Cancer\n",
       "144       1          1                Cancer                   Cancer\n",
       "380       1          1                Cancer                   Cancer\n",
       "132       0          0             No Cancer                No Cancer\n",
       "333       1          1                Cancer                   Cancer\n",
       "86        0          0             No Cancer                No Cancer\n",
       "250       0          0             No Cancer                No Cancer\n",
       "274       0          0             No Cancer                No Cancer\n",
       "257       0          0             No Cancer                No Cancer\n",
       "9         0          0             No Cancer                No Cancer\n",
       "468       0          0             No Cancer                No Cancer\n",
       "382       1          1                Cancer                   Cancer\n",
       "322       1          1                Cancer                   Cancer\n",
       "84        1          1                Cancer                   Cancer\n",
       "526       1          1                Cancer                   Cancer\n",
       "500       1          1                Cancer                   Cancer\n",
       "561       1          1                Cancer                   Cancer\n",
       "332       1          1                Cancer                   Cancer\n",
       "110       1          1                Cancer                   Cancer\n",
       "565       0          0             No Cancer                No Cancer\n",
       "203       0          0             No Cancer                No Cancer\n",
       "153       1          1                Cancer                   Cancer\n",
       "441       0          0             No Cancer                No Cancer\n",
       "182       0          0             No Cancer                No Cancer\n",
       "140       1          1                Cancer                   Cancer\n",
       "77        0          0             No Cancer                No Cancer\n",
       "408       0          0             No Cancer                No Cancer\n",
       "549       1          1                Cancer                   Cancer\n",
       "530       1          1                Cancer                   Cancer\n",
       "163       1          1                Cancer                   Cancer\n",
       "503       0          0             No Cancer                No Cancer\n",
       "148       1          1                Cancer                   Cancer\n",
       "486       1          1                Cancer                   Cancer\n",
       "75        0          0             No Cancer                No Cancer\n",
       "249       1          1                Cancer                   Cancer\n",
       "238       1          0                Cancer                No Cancer\n",
       "265       0          0             No Cancer                No Cancer"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set display options to show the full DataFrame without truncation\n",
    "pd.set_option('display.max_rows', None)  # Display all rows without truncation\n",
    "pd.set_option('display.max_columns', None)  # Display all columns without truncation\n",
    "pd.set_option('display.width', None)  # Allow wide DataFrames to fit the display\n",
    "pd.set_option('display.max_colwidth', None)  # Display full content of each column\n",
    "\n",
    "# Displaying the results DataFrame\n",
    "results_df  # Show the DataFrame with the adjusted display settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d89de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates the accuracy of the model by comparing predicted labels y_pred with actual labels y_test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generates a classification report including precision, recall, F1-score, and support for each class\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e626ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying the results\n",
    "print(\"Accuracy:\", accuracy)  # Print the accuracy of the model\n",
    "print(\"Classification Report:\\n\", class_report)  # Print the classification report of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c90ddaf",
   "metadata": {},
   "source": [
    "# Understanding Evaluation Metrics\n",
    "\n",
    "## Precision, Recall, F1-Score, and Support\n",
    "\n",
    "- **Precision**: How often are the model's positive predictions correct?\n",
    "  - `precision = TP / (TP + FP)`\n",
    "  - High precision means the model makes few mistakes when it predicts positive.\n",
    "  - Example: If the model says 10 flowers are setosa and 9 of them are actually setosa, precision is high.\n",
    "\n",
    "- **Recall**: How well does the model find all the actual positives?\n",
    "  - `recall = TP / (TP + FN)`\n",
    "  - High recall means the model misses few real positives.\n",
    "  - Example: If there are 10 setosa flowers and the model finds 9 of them, recall is high.\n",
    "\n",
    "- **F1-Score**: How well does the model balance precision and recall?\n",
    "  - `f1-score = 2 * (Precision * Recall) / (Precision + Recall)`\n",
    "  - It's useful when you need a balance of both.\n",
    "  - Example: If you need both high precision and high recall, the F1-Score shows how well the model does on both.\n",
    "\n",
    "- **Support**: How many examples are there for each class in the dataset?\n",
    "  - It shows how many instances of each class you have.\n",
    "  - Example: If you have 50 setosa flowers, 50 is the support for the setosa class.\n",
    "\n",
    "## Accuracy\n",
    "- **Accuracy**: The ratio of correctly predicted instances to the total instances.\n",
    "  - `accuracy = (TP + TN) / (TP + TN + FP + FN)`\n",
    "  - High accuracy means the model predicts correctly most of the time.\n",
    "  - Example: If the model correctly predicts 95 out of 100 instances, accuracy is 95%.\n",
    "\n",
    "## Macro Average\n",
    "- **Macro Average**: The average of precision, recall, and F1-score calculated for each class independently, then averaged.\n",
    "  - It treats all classes equally, regardless of their support.\n",
    "  - Useful when you want to evaluate the model's performance equally across all classes.\n",
    "  - Example: If you have three classes, the macro average precision is the average of the precision values for all three classes.\n",
    "\n",
    "## Weighted Average\n",
    "- **Weighted Average**: The average of precision, recall, and F1-score calculated for each class, weighted by the number of instances (support) of each class.\n",
    "  - It takes into account the imbalance in the dataset.\n",
    "  - Useful when you want to reflect the performance on the dataset as a whole, especially if there is class imbalance.\n",
    "  - Example: If one class is much larger than the others, the weighted average will give more importance to the performance on that class.\n",
    "\n",
    "## Why These Metrics Matter\n",
    "These metrics help you understand how well your model is performing:\n",
    "\n",
    "- **Precision**: Important when you need accurate positive predictions.\n",
    "- **Recall**: Important when you want to find all positive cases.\n",
    "- **F1-Score**: Important when you need a good balance between precision and recall.\n",
    "- **Support**: Helps you see how many examples of each class you have, giving context to the other metrics.\n",
    "- **Accuracy**: Gives an overall performance measure, useful for binary and balanced multiclass problems.\n",
    "- **Macro Average**: Important for evaluating performance equally across all classes.\n",
    "- **Weighted Average**: Important for reflecting the performance on the dataset as a whole, especially with class imbalance.\n",
    "\n",
    "Together, these metrics give a clear picture of your model's performance, especially in multiclass classification problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36875bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to create a confusion matrix heatmap with dynamic text color\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix heatmap with dynamic text color.\n",
    "\n",
    "    Parameters:\n",
    "    - cm : numpy array\n",
    "        Confusion matrix array to be visualized.\n",
    "    - title : str, optional\n",
    "        Title of the plot (default is 'Confusion Matrix').\n",
    "    - cmap : matplotlib colormap, optional\n",
    "        Colormap for the heatmap (default is plt.cm.Blues).\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)  # Display the confusion matrix as an image\n",
    "    plt.title(title)  # Set the title of the plot\n",
    "    plt.colorbar()  # Add a colorbar to the plot\n",
    "    tick_marks = np.arange(len(cm))  # Create tick marks based on the confusion matrix size\n",
    "    plt.xticks(tick_marks, ['0', '1'], rotation=45)  # Set x-axis tick labels and rotate them\n",
    "    plt.yticks(tick_marks, ['0', '1'])  # Set y-axis tick labels\n",
    "\n",
    "    # Formatting text inside the cells based on threshold\n",
    "    thresh = cm.max() / 2.  # Set threshold to determine text color\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):  # Iterate over the confusion matrix cells\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),  # Place text in the cell\n",
    "                 horizontalalignment=\"center\",  # Center-align the text\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")  # Set text color based on threshold\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to fit everything\n",
    "    plt.ylabel('Actual')  # Set the y-axis label\n",
    "    plt.xlabel('Predicted')  # Set the x-axis label\n",
    "    plt.show()  # Display the plot\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "import itertools  # Import itertools for product function\n",
    "\n",
    "plot_confusion_matrix(conf_matrix)  # Call the function with the confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ea3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset to a CSV file named 'breast_cancer_data.csv', without saving the index column\n",
    "df.to_csv('breast_cancer_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e1e0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the joblib library for saving and loading Python objects\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a00fb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained logistic regression model 'model' to a file named 'logistic_regression_model.pkl' using joblib\n",
    "joblib.dump(model, 'logistic_regression_model.pkl')\n",
    "\n",
    "# Loading the saved logistic regression model from 'logistic_regression_model.pkl' into 'loaded_model' using joblib\n",
    "loaded_model = joblib.load('logistic_regression_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "202071a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(np.array([[14.0, 20.0, 90.0, 500.0, 0.1, 0.2, 0.2, 0.1, 0.2, 0.1,\n",
    "                                   1.0, 1.0, 6.0, 80.0, 0.01, 0.05, 0.06, 0.02, 0.03, 0.007,\n",
    "                                   16.0, 30.0, 100.0, 600.0, 0.15, 0.4, 0.4, 0.15, 0.3, 0.08]]),\n",
    "                     columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b884a0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the new data: 0  (No Cancer)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sulaiman\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predict the class of the new data\n",
    "new_data_prediction = loaded_model.predict(new_data)  # Use the trained model to predict the class of new data\n",
    "\n",
    "# Interpret and print the prediction result\n",
    "if new_data_prediction[0] == 0:  # Check if the predicted class is 0\n",
    "    print(\"Prediction for the new data: 0  (No Cancer)\")  # Print result indicating no cancer\n",
    "else:\n",
    "    print(\"Prediction for the new data: 1 (Cancer)\")  # Print result indicating cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f5f06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_scaled = scaler.transform(new_data)  # Transforming the test data using the fitted scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e6437fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the new data: 0  (No Cancer)\n"
     ]
    }
   ],
   "source": [
    "# Predict the class of the new data\n",
    "new_data_prediction_scaled = loaded_model.predict(new_data_scaled)  # Use the trained model to predict the class of new data\n",
    "\n",
    "# Interpret and print the prediction result\n",
    "if new_data_prediction_scaled[0] == 0:  # Check if the predicted class is 0\n",
    "    print(\"Prediction for the new data: 0  (No Cancer)\")  # Print result indicating no cancer\n",
    "else:\n",
    "    print(\"Prediction for the new data: 1 (Cancer)\")  # Print result indicating cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b25ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
